{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b88ac4-5e8d-4d9b-90a0-c254069d4524",
   "metadata": {},
   "source": [
    "# Predicting Spotify Songs Popularity\n",
    "\n",
    "Author: Polina Adamovich\n",
    "\n",
    "Data source: [Tidy Tuesday project on Github](https://github.com/rfordatascience/tidytuesday/tree/main/data/2020/2020-01-21)\n",
    "\n",
    "### Table of contents:\n",
    "\n",
    "- #### A. EDA\n",
    "\n",
    "- #### B. Clustering\n",
    "\n",
    "- #### C. Models: Fitting & Interpretation\n",
    "\n",
    "- #### D. Models: Predictions\n",
    "\n",
    "- #### E. Models: Performance & Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c129d4-7a7f-48eb-b4b2-ab8184f54889",
   "metadata": {},
   "source": [
    "## A. EDA\n",
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697e4813-ba50-4c72-b551-752f5a586ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d837a4e-aa96-4127-a112-98fc96c7d64b",
   "metadata": {},
   "source": [
    "#### Read in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e0ba1a-e098-4a12-bbae-d7c8ec18b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_url = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv'\n",
    "\n",
    "df = pd.read_csv( songs_url )\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4e6b9e-16d8-4fcf-adc8-f5a4ac59f038",
   "metadata": {},
   "source": [
    "#### a. Basic information\n",
    "\n",
    "##### Show the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2628c8-27a7-409a-9231-cd9dee78f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cae61c-08c3-400b-aad1-df5540325993",
   "metadata": {},
   "source": [
    "The `df` DataFrame has 32,833 rows and 23 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ecc4a-0f04-4293-9e7f-d4b4d23fb814",
   "metadata": {},
   "source": [
    "##### Display the variable names and their associated data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c252c0c-df87-4493-86fd-771b59ac4d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdf2687-bd00-4e99-b946-34e82b74d8c6",
   "metadata": {},
   "source": [
    "##### Display the number of missing values for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563f8ee-427a-437e-8dd9-89ba4312c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe5bfbb-ea30-4e42-9cd7-469c86f1cfd7",
   "metadata": {},
   "source": [
    "There are three variables that have missing values: `track_name`, `track_artist` and `track_album_name`. Each of these variables is missing 5 values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0b5c63-ad9e-4a71-b368-af19e50112ce",
   "metadata": {},
   "source": [
    "##### Display the number of unique values for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91420081-f5a8-43cb-be03-c45c8bbb0292",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8554144-4d04-42d8-8f04-2dcd856ddf1b",
   "metadata": {},
   "source": [
    "### Cleaning the dataset\n",
    "\n",
    "According to the Tidy Tuesday github page `track_id` is a unique song ID. But we can see that there are less unique values for `track_id` than rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b1df5-9079-4297-88e0-fa1c7beb66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.track_id.value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeb2baa-a12e-4e2a-95f9-43c28b7069c5",
   "metadata": {},
   "source": [
    "We can see that some track ids have from 2 to 10 rows associated with them. Further exploration (not shown in this notebook for brevity) reveals that each row represents a track from an album within a specific playlist - meaning duplicates arise from the same track appearing in multiple playlists.\n",
    "\n",
    "Now I will check whether the duplication of the `track_id` is associated with changes in the output, `track_popularity`, and inputs of interest. We group the data by `track_id` and count the number of unique values for each feature of interest - including both the target `track_popularity` and the input features we might use in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff7d3d7-6bfd-4283-af45-aa11ea8478ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['track_id']).\\\n",
    "aggregate(num_track_pop_values = ('track_popularity', 'nunique'),\n",
    "          num_playlist_genre_values = ('playlist_genre', 'nunique'),\n",
    "          num_playlist_subgenre_values = ('playlist_subgenre', 'nunique'),\n",
    "          num_danceability_values = ('danceability', 'nunique'),\n",
    "          num_energy_values = ('energy', 'nunique'),\n",
    "          num_key_values = ('key', 'nunique'),\n",
    "          num_loudness_values = ('loudness', 'nunique'),\n",
    "          num_mode_values = ('mode', 'nunique'),\n",
    "          num_speechiness_values = ('speechiness', 'nunique'),\n",
    "          num_acousticness_values = ('acousticness', 'nunique'),\n",
    "          num_instrumentalness_values = ('instrumentalness', 'nunique'),\n",
    "          num_liveness_values = ('liveness', 'nunique'),\n",
    "          num_valence_values = ('valence', 'nunique'),\n",
    "          num_tempo_values = ('tempo', 'nunique'),\n",
    "          num_duration_values = ('duration_ms', 'nunique')).\\\n",
    "reset_index().\\\n",
    "nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80db10f3-2e01-49b8-b3ff-fc6259f535e2",
   "metadata": {},
   "source": [
    "We observe that some tracks appear with up to 5 different `playlist_genre` values and up to 10 different `playlist_subgenre` values. This is expected, since the same track can be included in multiple playlists with different themes or categorizations.\n",
    "\n",
    "To ensure each row in the dataset represents a unique track, I chose to filter the original dataset to include only tracks that appeared once and only once and created a new dataset `df_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1e3f7-fe7c-467c-b387-d57447b03175",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_counts = df.track_id.value_counts()\n",
    "unique_track_ids = track_counts[track_counts == 1].index\n",
    "df_clean = df[df.track_id.isin(unique_track_ids)]\n",
    "\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb1c8a-f9f3-46aa-9c4f-1469f72f9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0478e95e-d6ae-48eb-a471-559138d8de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "(32833 - 25190) / 32833"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5e9b9-fb63-47d1-8e30-77be360b5d93",
   "metadata": {},
   "source": [
    "I chose to remove all duplicate tracks, which reduced the dataset size by about 23%. The main benefit was making the data much simpler to work with, as I didn't have to figure out how to handle cases where the same song appeared in conflicting playlists (for example, a song listed in both a pop and a rock playlist). The primary cost, however, is the reduction in data size, which could slightly decrease the model's statistical power. I determined that the value of a simpler, more interpretable dataset was worth the trade-off of a smaller sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2855b5bf-527c-4be2-8d64-2e3d73331c8d",
   "metadata": {},
   "source": [
    "I'm treating the variable `mode` as a non-numeric column because it has low number of unique values - 2 - and because those numbers represent categories, not quantities. I will also treat column `key` as a non-numeric column for the same reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e551f-7510-4de3-b3ee-291fd390da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy=df_clean.copy()\n",
    "\n",
    "df_copy['key'] = df_copy['key'].astype('object')\n",
    "df_copy['mode'] = df_copy['mode'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f7f751-afe0-432f-b1cf-cfa30e9653bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Here I transformed the original target variable `track_popularity` into an object type variable `binary_outcome`  which will have 2 unique values: `1` if the song's popularity is over 50, and `0` overwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e79fba4-1ce3-4eb8-8e5e-460d673d3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['binary_outcome'] = np.where( df_copy.track_popularity > 50, 1, 0 )\n",
    "df_copy['binary_outcome'] = df_copy['binary_outcome'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73583d28-4792-4cb9-99dd-3739e5cb661b",
   "metadata": {},
   "source": [
    "#### b. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcf67b6-d040-472f-bf8f-2040c8b5cd79",
   "metadata": {},
   "source": [
    "##### 1. Counts of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f6e078-2ce4-4b85-95fb-e04fb42f8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_copy, x='playlist_genre', kind='count', hue='playlist_genre', aspect=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306ea40f-ae65-4c80-ba7a-fb8e96ec4c28",
   "metadata": {},
   "source": [
    "The bar chart above shows the distribution of songs across six different playlist genres in the cleaned dataset. While the genres are relatively balanced, rap stands out as the most represented genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e30282-8357-4a51-984e-4f177fa68b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_copy, x='mode', kind='count', hue='mode')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6228e0-c099-413d-b1e2-c295a6137585",
   "metadata": {},
   "source": [
    "While the distribution of songs across the two modes (1 - major, 0 - minor) is also relatively balanced, mode 1 is slightly more prevalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd9b51b-6342-4c27-a74d-c3bfd07eb63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_copy, x='key', kind='count', hue='key')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ff275e-5a39-40d2-bf2d-a098bd39adf2",
   "metadata": {},
   "source": [
    "The distribution of songs across the 12 musical keys is relatively balanced, with the exception of key 3, which has the fewest songs. Keys 0, 1, and 7 are the most common in the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b1feab-40e0-4fdf-ad55-61ca8aa67b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_copy, x='binary_outcome', kind='count', hue='binary_outcome')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f8ab7-9f23-4f40-baa0-e99c877c5415",
   "metadata": {},
   "source": [
    "This bar chart shows that our cleaned dataset contains roughly twice as many unpopular songs (where `track_popularity` is lower than 50) as popular ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d79f37-0b8d-4a00-b6dd-8e6aa0a2fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.binary_outcome.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69d816b-f64d-448a-be8a-6e6252412e27",
   "metadata": {},
   "source": [
    "More than 67% of the songs in the dataset are classified as unpopular (using a 50% threshold)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3051d55a-52db-4cca-b76c-a1e91f7a71d2",
   "metadata": {},
   "source": [
    "##### 2. Distributions of continuous variables\n",
    "\n",
    "To visualize marginal distributions for all continuous variables at once, I will first transform the database into the long format, which is preferred by Seaborn, and call it `df_lf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaaf42a-6028-4923-a9e0-ebc8a46c3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_copy.select_dtypes('number').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e05802-8c27-4d61-be47-e477cb4ff187",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_objects = df_copy.select_dtypes('object').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa2a53-785e-4f14-9e0b-735afbf9f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['rowid'] + df_objects.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7345d48-4628-47c4-bab2-99cf81d41b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lf = df_copy.reset_index().\\\n",
    "rename(columns={'index': 'rowid'}).\\\n",
    "melt(id_vars=id_cols, value_vars=df_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f58bd-208b-4dc0-807c-b5d8f7cdad04",
   "metadata": {},
   "source": [
    "I will now create density plots for all continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecabaed-975d-41fe-996d-31db114ae13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_lf, x='value', col='variable', kind='kde', col_wrap = 3,\n",
    "            facet_kws={'sharex':False, 'sharey':False},\n",
    "            common_norm=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987dbe36-c9b1-49fc-b3a0-6040447c4390",
   "metadata": {},
   "source": [
    "None of the distributions appear perfectly symmetric or unimodal - several exhibit multiple peaks, while others have long tails, indicating skewness. This suggests that the continuous variables deviate from a Gaussian distribution. Among them, the distributions of `danceability`, `valence`, `energy`, and `duration` are the most Gaussian-like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4ec78-e17d-4510-bf25-6560e664afbb",
   "metadata": {},
   "source": [
    "##### 3. Relationships between continuous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762e111d-7d7d-4d6e-920f-13325280b551",
   "metadata": {},
   "source": [
    "The pairsplot below shows the relationship between all continious variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b832383c-ffe1-4a49-9578-6bd902fd7d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df_copy, x_vars=['track_popularity', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms'],\n",
    "             y_vars=['track_popularity', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms'],\n",
    "             diag_kind='kde',\n",
    "             diag_kws={'common_norm': False})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4217e5d3-71a9-4361-947d-d7ec92d4a39f",
   "metadata": {},
   "source": [
    "There is a positive correlation between `loudness` and `energy`. Aside from this, the other scatterplots do not show any obvious linear or non-linear relationships, with the points generally appearing as unstructured clouds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43563072-c0a6-46e1-a536-3830df53fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(data = df_copy.loc[:, ['track_popularity', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']].corr(),\n",
    "            vmin=-1, vmax=1, center = 0,\n",
    "            cmap='coolwarm',\n",
    "            annot=True, annot_kws={'size': 7},\n",
    "            ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3e29d0-2f35-43c1-ab0a-88ac3557920c",
   "metadata": {},
   "source": [
    "The correlation plot above helps to see the relationships between continuous variables more clearly. It shows a somewhat strong positive correlation between `loudness` and `energy` and moderate negative correlation between `acousticness` and `energy`. Most other variable pairs show weak correlations, both positive and negative. The target variable, `track_popularity`, is only weakly correlated with other features - showing a slight positive correlation with `acousticness` and slight negative correlations with `energy`, `instrumentalness`, and `duration_ms`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d0245d-7588-4e8d-83b8-481916ffa74e",
   "metadata": {},
   "source": [
    "##### 4. Summaries of the continuous variables grouped by categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dda0be-d48c-48f4-b90f-dd1a9413f482",
   "metadata": {},
   "source": [
    "First, I will study distributions of all continuous variables grouped by `playlist_genre`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9712d0-1c2c-49da-96cf-bee1ac0b0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_lf, x='value', col='variable', col_wrap=3, kind='kde',\n",
    "            hue='playlist_genre',\n",
    "            facet_kws={'sharex': False, 'sharey': False},\n",
    "            common_norm=False,\n",
    "            palette='bright')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268c1edd-bb3b-4087-a957-3730448db384",
   "metadata": {},
   "source": [
    "The distributions of continuous variables such as `danceability`, `energy`, `speechiness`, `acousticness`, `instrumentalness`, `valence`, `tempo`, and `duration_ms` vary substantially across different playlist genres.\n",
    "\n",
    "The plot below shows distributions of all continuous variables grouped by `key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a7905a-0930-4703-8bd0-99e8a66ff3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_lf, x='value', col='variable', col_wrap=3, kind='kde',\n",
    "            hue='key',\n",
    "            facet_kws={'sharex': False, 'sharey': False},\n",
    "            common_norm=False,\n",
    "            palette='bright')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4172f829-750c-4703-bb34-2f076a705b74",
   "metadata": {},
   "source": [
    "While there are some subtle shifts, the distributions of the continuous variables are largely consistent across the different musical keys. This suggests that musical key is not a primary factor influencing these audio features.\n",
    "\n",
    "The plot below shows distributions of all continuous variables grouped by `mode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91860e04-6487-4397-a476-32bd941529fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_lf, x='value', col='variable', col_wrap=3, kind='kde',\n",
    "            hue='mode',\n",
    "            facet_kws={'sharex': False, 'sharey': False},\n",
    "            common_norm=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56526b6-2f3c-4d13-8690-462cfc2dda9f",
   "metadata": {},
   "source": [
    "The distributions of continuous variables appear largely similar across the two categories of `mode`. This suggests that `mode` may not have a strong influence on the distributions of these continuous features.\n",
    "\n",
    "I will now create a series of point plots to explore how the means of all continuous variables vary across 3 categorical variables (`playlist_genre`, `mode`, and `key`). Each facet represents a different continuous variable, the x-axis shows the categories of a selected categorical variable, and y-axis shows values of the continuous variable within each facet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f2696-0dec-42f4-a71f-0168f7b55bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df_lf, x='playlist_genre', y='value',col='variable', col_wrap=3, kind='point', hue='playlist_genre',\n",
    "            sharey=False, join=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb6b1b9-35f4-4616-a443-138d7918516b",
   "metadata": {},
   "source": [
    "The point plots above suggest meaningful differences in the mean values of continuous variables across some playlist genres. In particular, the facet showing the target variable `track_popularity` reveals that songs in pop, rap, rock, and Latin playlists tend to have higher average popularity, with overlapping confidence intervals. In contrast, songs in edm playlists have a significantly lower mean popularity, with a non-overlapping confidence interval - indicating a likely true difference in average popularity compared to the other genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f201d3-3c6b-4a4c-97c6-181ab32b911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df_lf, x='key', y='value',col='variable', col_wrap=3, kind='point', hue='key',\n",
    "            sharey=False, join=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490fefb-a0ee-45f8-9026-b35877ba1dd5",
   "metadata": {},
   "source": [
    "The point plots above suggest that there are meaningful differences in the means of some continuous variables grouped by `key`. Focusing on the facet showing the target variable `track_popularity`, we can see that the plot suggests some meaninful differences in the average popularity across different keys. For example, songs in key 8 have higher average popularity than songs in keys 2, 6, 7, and 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a991aa5-b3f3-4776-a8e1-4a81d6dba195",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df_lf, x='mode', y='value',col='variable', col_wrap=3, kind='point', hue='mode',\n",
    "            sharey=False, join=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd1c72e-42d4-4802-b9d6-66a207daaa22",
   "metadata": {},
   "source": [
    "The point plot above shows meaningful differences in the average values of track popularity, danceability, loudness, speechiness, and tempo depending on the mode of the song. Focusing on the facet for `track_popularity`, songs in mode 1 have higher average popularity than songs in mode 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a8b7b-7742-4d3e-8b03-e715010f04ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df_lf, x='binary_outcome', y='value',col='variable', col_wrap=3, kind='point', hue='binary_outcome',\n",
    "            sharey=False, join=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba6b79-3de4-4fd8-a633-cb5aeb1ab706",
   "metadata": {},
   "source": [
    "The point plot reveals statistically significant differences in the mean values of several audio features between popular and unpopular songs. Specifically, popular songs tend to have higher `danceability`, `loudness`, `acousticness`, while showing lower average `valence` and lower `energy`, `instrumentalness', 'liveness', and 'duration_ms`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f1e3c-c39a-49bc-80c6-be24cd036535",
   "metadata": {},
   "source": [
    "##### 4. Histograms and relationships between continuous inputs broken up by the outcome unique values\n",
    "\n",
    "The plot below shows the distributions of all continuous variables, grouped by `binary_outcome`, along the diagonal, as well as relationships between input continuous variables in the off-diagonal plots, also grouped by `binary_outcome`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4defc0fc-7319-4603-bf8b-e8eae3c88040",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df_copy, x_vars=['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms'],\n",
    "             y_vars=['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms'],\n",
    "             hue='binary_outcome',\n",
    "             diag_kind='kde',\n",
    "             diag_kws={'common_norm': False})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d26ac01-bc4b-4ab9-93a5-5b46f7d25400",
   "metadata": {},
   "source": [
    "Grouping the relationships between continuous variables by `binary_outcome` did not reveal any clear patterns or separation between the two classes. Across all scatterplots, the data points for both outcomes appear largely overlapping, suggesting little visual distinction between them.\n",
    "\n",
    "The histograms below show the distribution of each continuous input variable separately for the two categories of the `binary_outcome`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d5c794-1bca-4ce4-b83e-8c3d92aaf335",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_copy, x='danceability', col='binary_outcome', kind='hist')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f5acee-d68d-4798-8a79-185b4a9ca655",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_copy, x='energy', col='binary_outcome', kind='hist')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def49f1b-91d5-479d-aa70-6f367af66fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_copy, x='loudness', col='binary_outcome', kind='hist')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ca2537-55bb-4b0f-b24e-292fe3efae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_copy, x='speechiness', col='binary_outcome', kind='hist')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454a942-02f4-4146-88a2-5bb368b9b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_copy, x='acousticness', col='binary_outcome', kind='hist')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea2176c-21a5-4019-9633-cab38dc7734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_copy, x='instrumentalness', col='binary_outcome', kind='hist', bins=50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78c96e-dd23-4f9c-afa6-7f54fa0bb89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_copy, x='liveness', col='binary_outcome', kind='hist')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490fc031-bd97-4d87-940d-8a076b9df5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_copy, x='valence', col='binary_outcome', kind='hist')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf3ac7-db50-41ea-bc2a-c0cc94f242f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_copy, x='tempo', col='binary_outcome', kind='hist')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d4b2c7-b438-4d7f-982f-954f6440391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_copy, x='duration_ms', col='binary_outcome', kind='hist')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497af4a-7333-4730-9162-cf41f34d892a",
   "metadata": {},
   "source": [
    "The shapes of the distributions appear similar across the two outcome groups, suggesting that none of these continuous variables are strongly predictive of the outcome on their own. The apparent difference in the height of the histograms is due to the fact that category 0 has approximately twice as many observations as category 1. Since the default histograms display raw counts, the plot for category 0 naturally appears taller, even though the underlying distribution shapes are comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b535edfc-92ea-449b-a13d-3f343d8429dc",
   "metadata": {},
   "source": [
    "##### 5. Count the number of observations for each combination of outcome unique value and the categorical input unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd2a97f-9620-47e8-b222-6fc680ca1233",
   "metadata": {},
   "source": [
    "The dodged bar chart below shows how the 6 playlist genres are distributed across the 2 outcomes. The plot shows that most popular songs in the dataset are in the rap category and that edm has the biggest number of unpopular and the smallest number of popular songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a879a-1882-41fd-9523-5c90ecd05bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_copy, x='playlist_genre', hue='binary_outcome', kind='count', aspect=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bedb79-ccfd-470c-9a0b-5f07902e541f",
   "metadata": {},
   "source": [
    "The dodged bar chart below shows how the 12 musical keys are distributed across the 2 outcomes. We can see that songs in key 1 have the highest number of unpopular songs and the highest number of popular songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d869fb9f-ef44-44eb-bd91-a6033a6ea66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_copy, x='key', hue='binary_outcome', kind='count', aspect=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ed236-1c81-4c05-8e64-77c52ea4ba4e",
   "metadata": {},
   "source": [
    "The dodged bar chart below shows how the 2 modes are distributed across the 2 outcomes. Songs in mode 1 have the highest number of popular and the highest number of unpopular songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb229c4-d059-4ce6-8d47-9eb0445273e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_copy, x='mode', hue='binary_outcome', kind='count', aspect=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c99cf-00d2-4966-b423-96e593148cf2",
   "metadata": {},
   "source": [
    "In summary, the EDA revealed that while playlist genres, modes, and keys are relatively balanced in the cleaned dataset, rap is the most represented genre, mode 1 is slightly more common, and keys 0, 1, and 7 dominate, with key 3 being least frequent. The dataset contains about twice as many unpopular as popular songs. Continuous variables generally deviate from a Gaussian distribution, though `danceability`, `valence`, `energy`, and `duration` are closest to normality; `loudness` and `energy` show a strong positive correlation, while `acousticness` and `energy` are moderately negatively correlated. Differences in audio features emerge across genres, keys, and modes - pop, rap, rock, and Latin genres tend to have higher popularity, while edm has the lowest. Songs in certain keys (e.g., key 8) and mode 1 show higher average popularity. Popular songs tend to have higher `danceability`, `loudness`, and `acousticness` but lower `valence`, `energy`, `instrumentalness`, `liveness`, and `duration`. However, scatterplots grouped by outcome show substantial overlap between classes, suggesting that no single continuous variable is strongly predictive of popularity on its own. Finally, no obvious linear or nonlinear relationship was observed between the continous input variables and `track_popularity` (see *Supporting - EDA* for more)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7d4776-3148-4046-b470-f9ee8d91224e",
   "metadata": {},
   "source": [
    "## B. Clustering\n",
    "\n",
    "This time, I selected `danceability`, `valence`, and `speechiness` as input variables for clustering. This combination captures diverse aspects of the tracks making it a strong candidate for identifying meaningful groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8b4eda-b02e-4430-87a1-c1e646ff74e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_vars = df_copy[['danceability', 'speechiness', 'valence']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f472de8b-a54d-4b71-9951-80ee336b1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_vars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b15928c-16d2-48c3-aa46-dc3803b013a3",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "The distributions of `danceability` and `valence` are approximately Gaussian and require no transformation. However, `speechiness` is right-skewed, so I applied a log transformation to reduce the influence of extreme values. There is no strong correlation among these three variables which helps ensure that each variable contributes uniquely to the clustering process. None of these three variables have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ebad29-95b4-4b2e-a051-4c6888f3bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_vars['speechiness'] = np.log(df_cluster_vars.speechiness + 0.01)\n",
    "\n",
    "df_cluster_vars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f5d83-2ae4-47c0-97be-f06c396689ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df_copy, x='speechiness', kind='hist', kde=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4185800d-39fd-4bc8-ab02-b6d2d5bc3e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df_cluster_vars, x='speechiness', kind='hist', kde=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a97dc93-3c46-474d-8bdf-a3a1564f2cfe",
   "metadata": {},
   "source": [
    "Next, I'm going to check the scales of the three variables. The boxplot below shows that the magnitude and scale are dominated by `speechiness`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af717dcf-0b4c-4e34-8553-7ef5cea1a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_cluster_vars, kind='box', aspect=1.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d0746-0d1c-4267-992c-27040779cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed9a70-e21d-4071-a2ab-e78def79c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(df_cluster_vars) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162ce0a-938d-4853-9b7c-1d63fd5d920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot( data=pd.DataFrame(X, columns=df_cluster_vars.columns), kind='box', aspect=1.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f5959b-967a-4d9a-a8b4-a0ebc9d20bf3",
   "metadata": {},
   "source": [
    "Standardization is complete!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191c54ad-3544-480d-9af9-9469112077a2",
   "metadata": {},
   "source": [
    "Since the selected features are not highly correlated, I chose to cluster on the original variables rather than apply dimensionality reduction with PCA. This preserves the original interpretability of the variables, which would be lost if transformed into principal components.\n",
    "\n",
    "As at the proposal stage, I used KMeans for clustering. While hierarchical clustering is an alternative, it is typically limited to around 15,000 observations, whereas my cleaned dataset contains 25,190. KMeans is therefore more appropriate for the size of my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd2e1b5-6a6e-48c8-967a-e6f988232e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2294e30-9c00-43e6-bb5e-c2ba451ca584",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_vars_copy = df_cluster_vars.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac19d792-0758-4df3-bb13-8145908fd708",
   "metadata": {},
   "source": [
    "### Identifying the optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167874c2-4000-4fb3-a498-bf84221944ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tots_within = []\n",
    "\n",
    "K = range(1, 31)\n",
    "\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k, random_state=121, n_init=25, max_iter=500)\n",
    "    km = km.fit( X )\n",
    "\n",
    "    tots_within.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f3d694-e70c-489c-a039-9c8a3b4e2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot( K, tots_within, 'bo-' )\n",
    "ax.set_xlabel('number of clusters')\n",
    "ax.set_ylabel('total within sum of squares')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c127830e-b8bc-4d9c-aed9-a8d7ad428449",
   "metadata": {},
   "source": [
    "The Knee Bend shows that the total within-cluster sum of squares begins to level off around **5** clusters. While the curve doesn't become completely flat beyond that point, the rate of decrease seem to slow significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fb7745-9245-4255-88fa-bde7e7b42f6e",
   "metadata": {},
   "source": [
    "### Running KMeans for the optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3cf4f-ca2d-4c5b-8fa6-510665a78d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_5 = KMeans(n_clusters=5, random_state=121, n_init=25, max_iter=500).fit_predict( X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7dd341-ff76-4a43-b09c-b7020697294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_vars_copy['k5'] = pd.Series(clusters_5, index=df_cluster_vars_copy.index).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada04ab9-ae06-43ea-a7bc-ef6acc0e998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_vars_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9680067-4744-4220-a4d8-9e8be2ca14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_vars_copy.k5.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1fc252-39f1-48e3-a063-3658e3c6158e",
   "metadata": {},
   "source": [
    "### Visualizing clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c121b0f-7660-4c54-82e4-d832ba8d2f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = df_cluster_vars_copy, hue='k5', diag_kws={'common_norm': False})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4456b1-1132-4efb-a29b-4527a2307fe0",
   "metadata": {},
   "source": [
    "### Cluster-wise Summary and Distribution of Danceability, Speechiness, and Valence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ccdd3-0330-4ca8-9ee3-bad700ad8fd4",
   "metadata": {},
   "source": [
    "#### Danceability distribution across 5 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41a51a-a323-4f3e-a3af-41cb01bcba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_cluster_vars_copy, x='k5', y='danceability', kind='violin', hue='k5', aspect=1.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5efb8bc-8c59-4070-aff0-1ce0ffe5858b",
   "metadata": {},
   "source": [
    "Cluster 4 includes the most danceable songs, showing the highest median and a relatively tight distribution, though it overlaps somewhat with Clusters 0 and 2, which fall into an intermediate-to-high danceability range. These intermediate clusters share a similar range and show overlap with both Cluster 4 at the high end and Cluster 3, which occupies an intermediate range.\n",
    "\n",
    "Cluster 1 stands out as the least danceable group, with the lowest median and minimal overlap with the more danceable Cluster 3. Cluster 3 bridges the gap between the intermediate and low-danceability groups, overlapping significantly with Clusters 0 and 2, and only slightly with Cluster 1.\n",
    "\n",
    "While the clusters are not perfectly distinct, the contrast between the high median in Cluster 4 and the low median in Cluster 1 suggests that danceability meaningfully separates the most and least danceable groups. Additionally, the long lower tails seen in Clusters 1, 2, 3, and 4 indicate greater variability and some skewness in danceability values, especially toward the lower end of the scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202b512e-c219-4513-a858-8b1104429905",
   "metadata": {},
   "source": [
    "#### Speechiness distribution across 5 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be8eda-2d8d-496f-8cfc-2d0f5c1b7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_cluster_vars_copy, x='k5', y='speechiness', kind='violin', hue='k5', aspect=1.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5db004-456a-4a3d-9b91-2b962dd49b25",
   "metadata": {},
   "source": [
    "Clusters 0, 1, and 2 share similarly low median values, closely aligned distribution shapes, and fully overlapping violins, forming a clear low-speechiness group. In contrast, Clusters 3 and 4 exhibit higher, comparable medians and substantial overlap, suggesting a high-speechiness group.\n",
    "\n",
    "Notably, the two groups - Clusters 0, 1, and 2 and Clusters 3 and 4 - show no overlap in their interquartile ranges, indicating a clear separation between low and high speechiness clusters.\n",
    "\n",
    "Cluster 1 stands out slightly within the low-speechiness group due to its long tails on both ends, indicating greater variability in speechiness values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a6868b-d0dd-40b0-9761-d159870631cb",
   "metadata": {},
   "source": [
    "#### Valence distribution across 5 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ceee7f-a8c1-4c57-a2e3-e80e940ca651",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_cluster_vars_copy, x='k5', y='valence', kind='violin', hue='k5', aspect=1.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244b7b49-9fc4-42ea-a3d7-1a9c7577baec",
   "metadata": {},
   "source": [
    "Clusters 0, 1, and 3 have similar medians and substantially overlapping interquartile ranges, forming a low-valence group - that is, clusters with songs that tend to sound more negative.\n",
    "\n",
    "In contrast, Clusters 2 and 4 have higher median values and significantly overlapping interquartile ranges, indicating a higher-valence group associated with more positive-sounding songs.\n",
    "\n",
    "The slight overlap between Clusters 3 and 4 suggests that Cluster 3 shares some valence characteristics with the higher-valence group, despite generally aligning with lower-valence clusters. Additionally, the long upward tails of Clusters 1 and 3 and the long downward tail of Cluster 4 reflect greater variability in valence values at the distribution extremes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02e93ab-0aee-4eae-bdfb-67f27df3d51e",
   "metadata": {},
   "source": [
    "In summary, Clusters 0, 1, and 2 share low speechiness, with similar medians and overlapping distributions, while Clusters 3 and 4 form a distinct high-speechiness group. For danceability, Cluster 4 is the most danceable, Cluster 1 the least, and the others fall in between with overlapping ranges. Valence separates into a low group (Clusters 0, 1, and 3) and a high group (Clusters 2 and 4), with slight overlap between Clusters 3 and 4. Cluster 4 consistently stands out with high values across all three features, while Cluster 1 is low on all three and shows the greatest variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadb829f-dbc4-4377-89a7-f434f0c91402",
   "metadata": {},
   "source": [
    "### Comparing the cluster assignments to unique values of categorical inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b75c339-9237-4a4e-9e4e-ac8aa98e39ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_vars_copy['playlist_genre'] = df_copy.playlist_genre\n",
    "df_cluster_vars_copy['playlist_subgenre'] = df_copy.playlist_subgenre\n",
    "df_cluster_vars_copy['key'] = df_copy.key\n",
    "df_cluster_vars_copy['mode'] = df_copy['mode']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f19b29-cad0-449b-ad96-7fa343d47271",
   "metadata": {},
   "source": [
    "#### `paylist_genre` vs `k5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638d5b2-8d7b-4b5d-ab50-751896078ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(data = pd.crosstab( df_cluster_vars_copy.playlist_genre, df_cluster_vars_copy.k5, margins=True ), \n",
    "            annot=True, annot_kws={\"fontsize\": 15}, fmt='g',\n",
    "            cbar=True,\n",
    "            ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9cdae9-4060-49e0-8030-c0bf7526ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df_cluster_vars_copy, x='playlist_genre', hue='k5', kind='count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee53d4-1e9e-446f-a7de-fcccf5320c84",
   "metadata": {},
   "source": [
    "The heatmap and the dodged bar chart above show that while all clusters include a mix of genres, certain clusters have stronger associations with specific genres. For example, Cluster 1 is heavily represented by rock tracks, and Cluster 4 has the highest concentration of rap songs. Cluster 2, the largest group, appears relatively balanced across genres, while Cluster 0 leans more toward EDM and pop. Cluster 3 has a moderate concentration of rap and r&b. Overall, genre does not strictly define clusters, but some genre-based patterns are noticeable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e72d55-d9f6-4800-a4f5-cfbccb5c8f88",
   "metadata": {},
   "source": [
    "#### `key` vs `k5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f491831-96c6-49d3-b914-5332143e8923",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(data = pd.crosstab( df_cluster_vars_copy.key, df_cluster_vars_copy.k5, margins=True ), \n",
    "            annot=True, annot_kws={\"fontsize\": 13}, fmt='g',\n",
    "            cbar=True,\n",
    "            ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe40c64-b990-4606-833b-a8380e3ee162",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df_cluster_vars_copy, x='key', hue='k5', kind='count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbbfaa0-04e1-4866-9b2c-be047accd151",
   "metadata": {},
   "source": [
    "Similarly to the previous plots, the heatmap and the dodged bar chart above show that all clusters contain songs across a variety of musical keys. While some keys appear slightly more frequently, there is no strong or exclusive association between any particular key and any cluster. This suggests that musical key is not a major factor driving the clustering structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f7b8c-8e52-4d19-9ad5-ca8c60f3ed45",
   "metadata": {},
   "source": [
    "#### `mode` vs `k5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d9398-10aa-460e-a7e4-6e26b9afc5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(data = pd.crosstab( df_cluster_vars_copy['mode'], df_cluster_vars_copy.k5, margins=True ), \n",
    "            annot=True, annot_kws={\"fontsize\": 13}, fmt='g',\n",
    "            cbar=True,\n",
    "            ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691311ea-761c-441c-bff5-85d143ce919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df_cluster_vars_copy, x='mode', hue='k5', kind='count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b55aa-f390-4e07-b60e-b898cdecbf18",
   "metadata": {},
   "source": [
    "Similarly to the other visualizations, the heatmap and the dodged bar chart above show that all clusters contain a mix of both major and minor songs. Clusters 3 and 4 have a relatively balanced distribution of modes, while Clusters 0, 1, and 2 show a slight dominance of major songs (mode = 1). This suggests that modality is not a key factor influencing the clustering structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3d636-860d-4b6c-8b2e-49fe84420d3c",
   "metadata": {},
   "source": [
    "### Comparing the cluster assignments to unique values of the outcome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2bd8d7-8a8c-4de5-a9c6-a6f01cfc0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_vars_copy['binary_outcome'] = df_copy.binary_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a965bb46-a7c2-4668-a2a6-7cb57dff256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(data = pd.crosstab( df_cluster_vars_copy.binary_outcome, df_cluster_vars_copy.k5, margins=True ), \n",
    "            annot=True, annot_kws={\"fontsize\": 15}, fmt='g',\n",
    "            cbar=True,\n",
    "            ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e6a30b-5cdb-42fb-8276-25c56b377842",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df_cluster_vars_copy, x='binary_outcome', hue='k5', kind='count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93891c64-07a5-4621-a191-9612677529df",
   "metadata": {},
   "source": [
    "The heatmap and the dodged bar chart above show that all clusters contain a roughly similar proportion of songs with popularity above and below 50. This suggests that the binary popularity outcome is not a major factor driving the clustering structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31012db7-7454-48dd-9e35-f6a160f9b332",
   "metadata": {},
   "source": [
    "In summary, the clustering grouped songs into distinct profiles based on their `danceability`, `valence`, and `speechiness`. The key finding is that these clusters did not separate popular from unpopular songs, which reinforces our EDA's conclusion that no single audio feature is strongly predictive on its own. The analysis also revealed noticeable genre-based patterns within the clusters, supporting the EDA's finding that audio features differ across genres and suggesting this relationship is important to explore in the modeling stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af5906-f165-4547-ae17-d61d8c4abd9d",
   "metadata": {},
   "source": [
    "## C. Models: Fitting and Interpretation\n",
    "\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a321e20-b830-4817-9960-b0f9c3323573",
   "metadata": {},
   "source": [
    "In Section B (EDA), we saw that the distributions of the continuous input variables `loudness`, `speechiness`, `instrumentalness`, and `liveness`are not Gaussian-like. To address this, I applied a natural log transformation to `speechiness`, `instrumentalness`, and `liveness`. Because `loudness` includes negative values, neither the natural log nor square root transformation is applicable. Instead, I applied a cube root transformation to `loudness`, which works well with negative values and helps reduce skew.\n",
    "\n",
    "Although the distribution of `tempo` shows multiple peaks and is not perfectly symmetric, it is not strongly skewed. Therefore, I used it in its original form. The remaining continuous input variables were already approximately Gaussian-like and did not require transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179afcd2-d1f9-497d-be75-11d582214177",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_vars = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "\n",
    "df_numeric_inputs = df_copy[numeric_vars].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a6f3a-7099-4ec0-b85e-38e244f3536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric_inputs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d801a4-df78-4631-8271-b038e659debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric_inputs['loudness'] = np.cbrt(df_numeric_inputs.loudness)\n",
    "df_numeric_inputs['speechiness'] = np.log(df_numeric_inputs.speechiness + 0.01)\n",
    "df_numeric_inputs['acousticness'] = np.log(df_numeric_inputs.acousticness + 0.01)\n",
    "df_numeric_inputs['instrumentalness'] = np.log(df_numeric_inputs.instrumentalness + 0.01)\n",
    "df_numeric_inputs['liveness'] = np.log(df_numeric_inputs.liveness + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e3c64-c01e-43ca-95bd-3f764dae8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric_inputs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba330530-c617-4026-89bc-38660533b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot( data=df_numeric_inputs, kind='box', aspect=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18560846-0310-4bcb-9382-7459197b8b63",
   "metadata": {},
   "source": [
    "The boxplot above shows that the magnitude and scale are dominated by `duration_ms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ea23f-adee-4b29-870e-3a5bcc632e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric_scaled = pd.DataFrame(StandardScaler().fit_transform(df_numeric_inputs),\n",
    "                                 columns=df_numeric_inputs.columns, \n",
    "                                 index=df_numeric_inputs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14792727-42a0-4958-9102-a7261da2664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df_numeric_scaled, kind='box', aspect=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5cca49-504f-4c25-8595-c6f18c4ed297",
   "metadata": {},
   "source": [
    "Standardization is complete!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1707b6fa-b9c7-4674-88a0-75980b9f963e",
   "metadata": {},
   "source": [
    "### Creating a dataset with preprocessed continuous input variables, categorical input variables, and `binary_outcome`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c8953-cb49-4d01-8ccc-8ccc66da2d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling = df_numeric_scaled.copy()\n",
    "df_modeling['playlist_genre'] = df_copy.playlist_genre\n",
    "df_modeling['key'] = df_copy.key\n",
    "df_modeling['mode'] = df_copy['mode']\n",
    "df_modeling['binary_outcome'] = df_copy.binary_outcome.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372bd9c-15a3-4f19-a238-6fcec3d4681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52196000-326f-40b7-bcc7-0778919f4189",
   "metadata": {},
   "source": [
    "### Defining a list of formulas for eight models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f1a5b-a1c4-441c-9ffc-c10a670c1f48",
   "metadata": {},
   "source": [
    "I will fit and evaluate eight distinct logistic regression models to predict song popularity. This set includes six standard models required by the project instructions, progressing from a simple baseline to complex interaction models. \n",
    "\n",
    "In addition, I will test two custom models. The first (Model 7) is directly motivated by my EDA, which revealed that the distributions of key audio features like danceability and energy vary significantly across playlist genres. This model tests the hypothesis that the \"recipe\" for a popular song is different for each genre. \n",
    "\n",
    "The second (Model 8) is an exploratory model developed after finding no clear linear or U-shaped patterns in my initial scatter plots. This model tests a different non-linear hypothesis: that the relationship between a song's popularity and its tempo is not linear, but cyclical. This theory explores the idea that certain BPM ranges, like those ideal for activities such as dancing or driving, could be more popular than others.\n",
    "\n",
    "Thus, my list includes the following models:\n",
    "* Model 1: intercept-only or constant average model\n",
    "* Model 2: categorical inputs with additive features\n",
    "* Model 3: continuous inputs with linear additive features\n",
    "* Model 4: all inputs (continuous and categorical) with linear additive features\n",
    "* Model 5: continuous inputs with linear main effect and pair-wise interactions\n",
    "* Model 6: interaction between categorical and continuous inputs (including main effects)\n",
    "* Model 7: main effects plus the interaction between `playlist_genre` and a targeted subset of features\n",
    "* Model 8: cyclical (sine) `tempo` feature interacting with with playlist_genre interaction, plus main effects of other key audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da3d529-e65c-48e7-88ec-3101639ce46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_list = ['binary_outcome ~ 1', # intercept-only model\n",
    "                'binary_outcome ~ playlist_genre + key + mode', # categorical inputs with additive features\n",
    "                'binary_outcome ~ danceability + energy + loudness + speechiness + acousticness + instrumentalness + liveness + valence + tempo + duration_ms', # continuous inputs with linear additive features\n",
    "                'binary_outcome ~ danceability + energy + loudness + speechiness + acousticness + instrumentalness + liveness + valence + tempo + duration_ms + playlist_genre + key + mode', # all inputs (continuous and categorical) with linear additive features\n",
    "                'binary_outcome ~ (danceability + energy + loudness + speechiness + acousticness + instrumentalness + liveness + valence + tempo + duration_ms)**2', # continuous inputs with linear main effect and pair-wise interactions\n",
    "                'binary_outcome ~ (playlist_genre + key + mode) * (danceability + energy + loudness + speechiness + acousticness + instrumentalness + liveness + valence + tempo + duration_ms)', # interaction between categorical and continuous inputs (including main effects)\n",
    "                'binary_outcome ~ playlist_genre * (danceability + energy + speechiness + instrumentalness + valence + tempo)', # interaction between playlist_genre and a targeted subset of continuous features\n",
    "                'binary_outcome ~ playlist_genre * np.sin(tempo) + danceability + energy + acousticness'] # cyclical (sine) tempo feature interacting with with playlist_genre interaction, plus main effects of other key audio features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1919282a-c175-45c4-877e-34664164d5a5",
   "metadata": {},
   "source": [
    "### Fitting the models, checking their coefficients, and showing the performance on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f5e854-eff0-4294-b9eb-49a96edfb9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186d1834-f721-49bf-b73d-4303e1118298",
   "metadata": {},
   "source": [
    "I will define a single function to streamline the analysis. For any given model, this function will automatically fit the model, analyze its coefficients (number, significance, and magnitude), and calculate all required performance metrics (Accuracy, Sensitivity, Precision, Specificity, FPR, F1 score, and ROC AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752aeeea-6fe9-45a3-8caa-82f8661a940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_analyze_logistic(mod_name, a_formula, train_data, threshold=0.5):\n",
    "    a_mod = smf.logit(formula=a_formula, data=train_data).fit()\n",
    "\n",
    "    params = a_mod.params\n",
    "    pvalues = a_mod.pvalues\n",
    "    significant_params = params[pvalues < 0.05]\n",
    "\n",
    "    top_2_features = []\n",
    "    if len(significant_params) > 0:\n",
    "        top_2_features = (significant_params ** 2).sort_values(ascending=False).head(3).index.tolist()\n",
    "    \n",
    "    train_copy = train_data.copy()\n",
    "    train_copy['pred_probability'] = a_mod.predict( train_data )\n",
    "    \n",
    "    train_copy['pred_class'] = np.where( train_copy.pred_probability > threshold, 1, 0 )\n",
    "\n",
    "    TN, FP, FN, TP = confusion_matrix( train_copy.binary_outcome.to_numpy(), train_copy.pred_class.to_numpy() ).ravel()\n",
    "    \n",
    "    Accuracy = (TN + TP) / (TN + FP + FN + TP)\n",
    "    Sensitivity = (TP) / (TP + FN)\n",
    "    Precision = (TP) / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    Specificity = (TN) / (TN + FP)\n",
    "    FPR = 1 - Specificity\n",
    "    F1_Score = 2 * (Precision * Sensitivity) / (Precision + Sensitivity) if (Precision + Sensitivity) > 0 else 0\n",
    "    ROC_AUC = roc_auc_score( train_copy.binary_outcome.to_numpy(), train_copy.pred_probability.to_numpy() )\n",
    "\n",
    "    res_dict = {'model_name': mod_name,\n",
    "                'model_formula': a_formula,\n",
    "                'num_coefs': len(a_mod.params),\n",
    "                'num_sign_coefs': len(significant_params),\n",
    "                'sign_coefs_&_their_values': [significant_params.to_dict()],\n",
    "                'top_2_features': [top_2_features],\n",
    "                'Accuracy': Accuracy,\n",
    "                'Sensitivity': Sensitivity,\n",
    "                'Precision': Precision,\n",
    "                'Specificity': Specificity,\n",
    "                'FPR': FPR,\n",
    "                'F1 Score': F1_Score,\n",
    "                'ROC_AUC': ROC_AUC}\n",
    "\n",
    "    return pd.DataFrame(res_dict, index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8960662-646d-4e3f-adc0-711b321d7cbb",
   "metadata": {},
   "source": [
    "#### Model 1. Intercept-only or constant average model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc296740-1477-458b-82d2-13c74c39eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b61429c-a0b3-46d6-b238-8d20a700e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm_1 = smf.logit(formula=formula_list[0], data=df_modeling).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dbea66-3927-4bd8-a2fd-e3258854704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm_1.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c728dda-e4dc-4b6e-8b67-5966ad7e3811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling_copy = df_modeling.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb89004e-b859-45d2-9d1a-5939d865f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling_copy['pred_probability_M1'] = fit_glm_1.predict(df_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa9676-841d-4980-9a10-ce89c662845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling_copy['pred_class_M1'] = np.where(df_modeling_copy.pred_probability_M1 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208e2352-d7d5-4037-a966-912cb861b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(pd.crosstab(df_modeling_copy.binary_outcome, df_modeling_copy.pred_class_M1, margins=True),\n",
    "            annot=True, annot_kws={'size': 20}, fmt='3d')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2037d4-801e-4a40-8b4d-a33f065052be",
   "metadata": {},
   "source": [
    "As we can see from the confusion matrix above, the model doesn't classify any songs as \"popular\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19894c05-0648-4b61-a8aa-238a2b94cf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_results = fit_and_analyze_logistic(mod_name='Model 1', a_formula=formula_list[0], train_data=df_modeling, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff5825-e9f4-4e1a-80cb-432d18496fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce931dd-ba4f-4be5-8f7b-9bb1f46639ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling_copy.pred_probability_M1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774eb0dd-d86d-4f18-a80c-140e15854f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling.binary_outcome.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da0bbff-2dc8-4008-af84-3d72a20bfa3d",
   "metadata": {},
   "source": [
    "This model serves as a simple baseline. With no predictor variables, it calculates the average likelihood of a song being popular across the entire dataset.\n",
    "\n",
    "The model's single coefficient, the intercept (approximately -0.72), is statistically significant. This model predicts the same probability of being popular - approximately 33% - for every song. Because this constant predicted probability of 33% is below the 0.5 decision threshold, the model logically classifies every song as \"not popular\". This directly explains its performance metrics. \n",
    "* The accuracy is approximately 0.67, which simply reflects the class imbalance in the dataset; 67% of all songs belong to the \"not popular\" (majority) class. The model gets them all right by default. \n",
    "* The sensitivity is 0. Because the model never predicts a song as popular, it fails to correctly identify any of the truly popular songs. \n",
    "* The precision is also 0. Since the model makes no positive predictions, the number of True Positives is zero, resulting in a precision score of 0. \n",
    "* The specificity is a perfect 1, and therefore the FPR is 0. This is because the model correctly classifies every truly unpopular song as \"not popular\". \n",
    "* The F1 Score is 0, which is expected as it balances precision and sensitivity. A score of 0 indicates a complete failure to identify the positive class.\n",
    "* The ROC AUC is 0.5, which confirms the model has no ability to distinguish between popular and unpopular songs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e64bbd-4e79-406a-b59a-a8c5d125e30c",
   "metadata": {},
   "source": [
    "#### Model 2. Categorical inputs with additive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac226fe4-20f2-4d55-898c-bc5b4039ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd1d24-996b-4910-ae7c-82a4f2418406",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm_2 = smf.logit(formula=formula_list[1], data=df_modeling).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff078ff-9077-48d8-9525-c31da430b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling_copy['pred_probability_M2'] = fit_glm_2.predict(df_modeling)\n",
    "df_modeling_copy['pred_class_M2'] = np.where(df_modeling_copy.pred_probability_M2 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f1694-acd7-4306-8ab8-71424ad3b1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(pd.crosstab(df_modeling_copy.binary_outcome, df_modeling_copy.pred_class_M2, margins=True),\n",
    "            annot=True, annot_kws={'size': 20}, fmt='3d')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5df785-4101-4e8e-bdf1-c0f4849823d2",
   "metadata": {},
   "source": [
    "Similarly to the intercept-only model, Model 2 does not classify any songs as \"popular\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3718a81-550f-446d-8a31-23a775e1093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_results = fit_and_analyze_logistic(mod_name='Model 2', a_formula=formula_list[1], train_data=df_modeling, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e86f1c-2aab-4690-a5ec-350a6992bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592e1db9-55d9-4607-924d-9b20cab579ea",
   "metadata": {},
   "source": [
    "This model, which includes categorical inputs `playlist_genre`, `key`, and `mode` as predictors, has 18 coefficients, with 7 being statistically significant. This indicates that we can be confident that these 7 features have a non-zero effect on a song's popularity and that we can trust the direction of that relationship as indicated by the coefficients' signs. Below is the full list of all statistically significant features and their values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb823fa1-30e6-4a50-809d-cf2092379b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_results['sign_coefs_&_their_values'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8935fc0b-ceef-49e8-b9b3-71ad1d12e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_results.top_2_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493507d-a152-4615-b1ff-823e911666a8",
   "metadata": {},
   "source": [
    "The two features with the most impactful coefficients are the pop (around 1.23) and rock (around 1.20) genres. These are part of a broader pattern where five genres in total - including rap, latin, and r&b - all have a statistically significant positive association with popularity compared to the edm baseline. This provides strong evidence that a song's genre has a non-zero effect on its popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f175b-71f8-4f34-960b-dc7126486f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling_copy.pred_probability_M2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c956f2a-e57e-484f-b874-1dad04fdc4dc",
   "metadata": {},
   "source": [
    "The highest predicted probability for any song is approximately 0.43. Because no prediction crosses the 0.5 decision threshold, this model still classifies all songs as \"not popular,\" just like the intercept-only baseline. Consequently, all performance metrics that depend on the final class predictions - Accuracy, Sensitivity, Precision, and F1 Score - are identical to Model 1. For example, the Sensitivity is 0 because no popular songs are correctly identified.\n",
    "\n",
    "The key improvement is the ROC AUC, which increased from the baseline of 0.5 to roughly 0.60. This shows the model now has a weak but real ability to distinguish between the classes. Although its predicted probabilities don't cross the 0.5 threshold, it has learned to give slightly higher scores to popular songs than to unpopular ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a43f0f-2789-46e5-9f1d-759e693d6394",
   "metadata": {},
   "source": [
    "#### Model 3. Continuous inputs with linear additive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7700dc-63e7-42bb-83ce-267dbd791766",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8419d33-fe3b-411f-ad93-b0d5c4e4a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm_3 = smf.logit(formula=formula_list[2], data=df_modeling).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04660d2c-e702-422f-b779-ce73458eeba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling_copy['pred_probability_M3'] = fit_glm_3.predict(df_modeling)\n",
    "df_modeling_copy['pred_class_M3'] = np.where(df_modeling_copy.pred_probability_M3 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3548619-34e5-4ef0-b714-4b115537d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(pd.crosstab(df_modeling_copy.binary_outcome, df_modeling_copy.pred_class_M3, margins=True),\n",
    "            annot=True, annot_kws={'size': 20}, fmt='3d')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe42f0-459d-4438-8594-e259295649d5",
   "metadata": {},
   "source": [
    "Unlike the previous models, Model 3 correctly classifies some songs as popular, though the number of songs it predicts as popular is much smaller than the total number of truly popular songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50a6ff-66e8-43b5-b263-edd79208982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_results = fit_and_analyze_logistic(mod_name='Model 3', a_formula=formula_list[2], train_data=df_modeling, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd7745-9371-4768-8a45-c852b6ed2d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb71b44f-147f-43d0-9c2a-cfa80f004aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling_copy.pred_probability_M3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15be3c1c-a44d-4dc9-918d-6b7773603d3d",
   "metadata": {},
   "source": [
    "This model, which includes continuous inputs with linear additive features as predictors, has 11 coefficients, with 10 being statistically significant. This indicates that we can be confident that these 10 audio features have a non-zero effect on a song's popularity and that we can trust the direction of that relationship as indicated by the coefficients' signs. Below is the full list of all statistically significant features and their values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3d158e-a7a2-4301-a457-ec22831878fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_results['sign_coefs_&_their_values'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dceeb64-3050-4467-b582-4e33c3dd2a3a",
   "metadata": {},
   "source": [
    "The two coefficients with the highest magnitude apart from the intercept (around -0.76) are energy (around -0.30) and loudness (around 0.25). This indicates that, after controlling for other factors, an increase in a song's loudness is associated with a higher likelihood of it being popular, while a corresponding increase in energy is associated with a lower likelihood. It's important to note that energy and loudness are moderately correlated (0.68). While this does not impact the model's overall predictive power, the individual coefficients for these two features should be interpreted with caution, as the model may have difficulty separating their unique effects.\n",
    "\n",
    "A key improvement is that the model's predicted probabilities now go as high as 0.87, so unlike the previous models, it now classifies some songs as \"popular.\" The model's performance reveles a clear trade-off: the model's primary strength is its very high specificity (around 0.98), which means it is excellent at correctly identifying unpopular songs. This results in a low FPR of just 1.6% which means the model incorrectly flags only 1.6% of the truly \"unpopular\" songs as \"popular\".\n",
    "\n",
    "However, this high specificity comes at the cost of extremely low sensitivity (around 0.03), as the model finds only 3% of all truly popular songs. This poor performance on the positive class is also reflected in the Precision (around 0.47), which shows the model is correct less than half the time it predicts \"popular,\" and the very low F1 Score (aroud 0.05), which confirms the model is not well-balanced, as its performance on the positive class is poor.\n",
    "\n",
    "While the accuracy (around 0.67) is misleading due to class imbalance, the ROC AUC of 0.62 is the most reliable indicator. It confirms this model has a modest but improved ability to distinguish between classes compared to the baseline and Model 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6667bb-7284-4737-9942-58e75036f908",
   "metadata": {},
   "source": [
    "#### Model 4. All inputs (continuous and categorical) with linear additive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d701c-301c-47cd-a18a-4c0a33b77974",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867787a4-7a50-4316-869f-f6f6a1aa10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm_4 = smf.logit(formula=formula_list[3], data=df_modeling).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df194ffc-b6fc-490e-a853-a6515fbefee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling_copy['pred_probability_M4'] = fit_glm_4.predict(df_modeling)\n",
    "df_modeling_copy['pred_class_M4'] = np.where(df_modeling_copy.pred_probability_M4 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846062b-50cf-4c96-bdec-67837684419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(pd.crosstab(df_modeling_copy.binary_outcome, df_modeling_copy.pred_class_M4, margins=True),\n",
    "            annot=True, annot_kws={'size': 20}, fmt='3d')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59742f13-79b8-48fc-9f53-f8bcd36ffe73",
   "metadata": {},
   "source": [
    "Similar to Model 3, Model 4 correctly classifies some songs as popular. However, it still fails to identify a large portion of the truly popular songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b911b05b-3095-4996-b021-a24f83df0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_results = fit_and_analyze_logistic(mod_name='Model 4', a_formula=formula_list[3], train_data=df_modeling, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724caa08-9238-486e-a129-e7bba45d729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d52b8dd-f430-4964-8756-a1569046fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling_copy.pred_probability_M4.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474c08d5-206c-4897-b34c-baa65471d30e",
   "metadata": {},
   "source": [
    "This model, which includes all inputs with linear additive features, has 28 coefficients, with 15 being statistically significant.  Below is the full list of all statistically significant features and their values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc48fe9-29c2-4674-be94-c66f8c5b467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_results['sign_coefs_&_their_values'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4bd0ca-5592-4909-96a9-8153cf858d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_results.top_2_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df300b6a-fbaa-4cf3-b2d1-2ee8d16a288b",
   "metadata": {},
   "source": [
    "Among the model's features, the two with the highest magnitude coefficients are both genres: playlist_genre[T.rock] (around 1.40) and playlist_genre[T.pop] (around 1.08). This shows that even after accounting for a song's specific audio features, its genre has a strong association with its popularity. Compared to the edm baseline genre, songs in the rock and pop categories are significantly more likely to be popular, with rock showing the strongest effect.\n",
    "\n",
    "We can also see some effects from continuous features. For example, higher loudness (around 0.33) is associated with an increased likelihood of being popular, while higher energy (around -0.30) is associated with a decreased likelihood. This helps to understand of what a \"popular\" song in this dataset can look like. It is important, however, to interpret the individual strength of these two effects with caution, as energy and loudness are moderately correlated in the data.\n",
    "\n",
    "This model shows a clear, though modest, improvement in performance over previous models. The ROC AUC increased to around 0.66, indicating better overall ability to distinguish between classes.\n",
    "\n",
    "The most significant improvement is in the model's ability to find positive cases. The sensitivity increased to 0.085 and the F1 Score rose to 0.14. While still low, their values are higher than in Model 3. At the same time, this improvement comes with a trade-off, as specificity dropped to around 0.95, which means the model makes slightly more false positive errors to find more true positives. The accuracy (around 0.67) remains a misleading metric due to the class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dcdf0b-bc3d-4242-a2ab-7f4c961517bb",
   "metadata": {},
   "source": [
    "#### Model 5. Continuous inputs with linear main effect and pair-wise interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f6e6a1-bd24-4e3c-9ac9-2d224cf7e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2bbda3-565c-4e02-9618-d3bb133f33e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm_5 = smf.logit(formula=formula_list[4], data=df_modeling).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900f4cc8-533e-4c46-a796-1008c06f94a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling_copy['pred_probability_M5'] = fit_glm_5.predict(df_modeling)\n",
    "df_modeling_copy['pred_class_M5'] = np.where(df_modeling_copy.pred_probability_M5 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee19da9-54db-4bb2-bf26-a81bb278fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(pd.crosstab(df_modeling_copy.binary_outcome, df_modeling_copy.pred_class_M5, margins=True),\n",
    "            annot=True, annot_kws={'size': 20}, fmt='3d')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ce99e-04b6-44a2-851a-385b9f8142f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5_results = fit_and_analyze_logistic(mod_name='Model 5', a_formula=formula_list[4], train_data=df_modeling, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85218385-2d9d-45e0-867e-90ace8b83c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a35c617-7bdf-4f53-bea0-1debcd65be45",
   "metadata": {},
   "source": [
    "This model adds significant complexity by including all possible two-way interactions between the continuous features. It has 56 coefficients, with 27 being statistically significant. Below is the full list of all statistically significant features and their values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de27b15-937f-4227-9e20-fd845ac80f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5_results['sign_coefs_&_their_values'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a01ca2-f5db-44ef-9d8f-66f61e150c70",
   "metadata": {},
   "source": [
    "The two statistically significant features with the highest magnitude are the and energy (around -0.31) and loudness (around 0.28). The key new finding is the presence of numerous significant interaction terms. For example, the significant negative interaction between energy and loudness suggests that the relationship is not simple; the positive effect of a song being loud may be reduced if the song is also very energetic. Similarly to Model 3 and 4, it is important here to interpret the individual strength of the effects energy and loudness with caution, as they are moderately correlated.\n",
    "\n",
    "Despite the added complexity, this model's performance did not improve over the simpler Model 4. The ROC AUC decreased slightly to around 0.64, and the F1 Score also fell to around 0.12. While precision slightly increased to 0.54, sensitivity dropped to around 0.065, meaning the model is now even worse at identifying popular songs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9e051c-ba87-41f7-b5b1-01f0a5cb5163",
   "metadata": {},
   "source": [
    "#### Model 6. Interaction between categorical and continuous inputs (including main effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118347c4-459a-4cad-9a63-34bbfa8ef800",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fffaed-3085-415e-a9b3-f0a349e5fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm_6 = smf.logit(formula=formula_list[5], data=df_modeling).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc047d-1f38-4e65-be6a-d6493fc64e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling_copy['pred_probability_M6'] = fit_glm_6.predict(df_modeling)\n",
    "df_modeling_copy['pred_class_M6'] = np.where(df_modeling_copy.pred_probability_M6 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6dea19-d042-4ac5-9d83-0e97d47ca8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(pd.crosstab(df_modeling_copy.binary_outcome, df_modeling_copy.pred_class_M6, margins=True),\n",
    "            annot=True, annot_kws={'size': 20}, fmt='3d')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b42c4a-9d26-4993-998f-af83426e1152",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6_results = fit_and_analyze_logistic(mod_name='Model 6', a_formula=formula_list[5], train_data=df_modeling, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9041331-c393-4ffe-ad11-26c6e5da6519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_6_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0c54b-1a98-48af-8e4e-9bf499d6db53",
   "metadata": {},
   "source": [
    "Model 6, which includes interaction between categorical and continuous inputs (including main effects), has 198 coefficients, with 36 of them being statistically significant. Below is the full list of all statistically significant features and their values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cdff41-3b9e-4724-b7b3-ea0262d4f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6_results['sign_coefs_&_their_values'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f58eeea-6ca2-4fa3-bc1e-833ee2848e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6_results.top_2_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abee561-a0c4-4869-b33e-1be9115fd66f",
   "metadata": {},
   "source": [
    "The two statistically significant features with the highest magnitude are the and playlist_genre[T.rock] (around 1.07) and playlist_genre[T.pop] (around 0.97). We also see many significant interaction terms in this model. This suggests that the effect of an audio feature (such as danceability, etc.) on a track's popularity is not universal and it may be changing depending on the song's genre and musical key.\n",
    "\n",
    "This model shows better performance than Models 1-5. The ROC AUC improved to 0.68, and the F1 Score saw a substantial increase to 0.25, indicating a much better balance between precision and sensitivity. With sensitivity improving to around 0.16, this model is better at identifying popular songs. At the same time specificity decreased to 0.94, so the model makes more false positive errors to capture more true positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c870fd-3fde-4ac1-a568-60eba5c63ec5",
   "metadata": {},
   "source": [
    "#### Model 7. Additional model #1: Interaction between `playlist_genre` and a targeted subset of continuous features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbcbdc2-69bc-4182-bc9f-b48cfa3197a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_list[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2121b1-fcaa-425f-8117-4b6511701b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm_7 = smf.logit(formula=formula_list[6], data=df_modeling).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8a026-9475-4e1d-a927-b667b07ea283",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling_copy['pred_probability_M7'] = fit_glm_7.predict(df_modeling)\n",
    "df_modeling_copy['pred_class_M7'] = np.where(df_modeling_copy.pred_probability_M7 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa68603-556d-43e2-8287-50711c177693",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(pd.crosstab(df_modeling_copy.binary_outcome, df_modeling_copy.pred_class_M7, margins=True),\n",
    "            annot=True, annot_kws={'size': 20}, fmt='3d')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b4bc83-e63a-4c75-8a28-0d0e017750a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7_results = fit_and_analyze_logistic(mod_name='Model 7', a_formula=formula_list[6], train_data=df_modeling, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e740577-ef40-4d54-bb9f-2c51913574e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84acfdd4-2769-4484-95b1-ee4583d93388",
   "metadata": {},
   "source": [
    "Model 7, which includes interaction between `playlist_genre` and six continuous input variables, has 42 coefficients, half of which are statistically significant. Below is the full list of all statistically significant features and their values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d92518e-6e78-482c-a718-437634f40ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7_results['sign_coefs_&_their_values'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0139452-6465-4efb-8323-685e03e442ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7_results.top_2_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4670150-bb51-4675-ac84-c5afd29395af",
   "metadata": {},
   "source": [
    "The main effects for playlist_genre[T.pop] (around 0.97) and playlist_genre[T.rock] (around 0.97) remain the features with the highest magnitude. The significant interaction terms reveal more specific relationships; for example, the positive coefficient for playlist_genre[T.rap]:danceability suggests that danceability has a stronger positive effect on popularity for rap songs compared to the edm genre (reference group).\n",
    "\n",
    "This simpler model represents a significant decrease in performance from the more comprehensive interaction model (Model 6). The ROC AUC dropped to 0.64, and the F1 Score fell sharply to 0.06. This is driven by the sensitivity returning to a low level of 0.03, indicating the model has poor ability to identify popular songs. This suggests that the features and interactions removed from this model were important for its predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd3ccda-b682-4743-8ed5-f8c5047f8cc0",
   "metadata": {},
   "source": [
    "#### Model 8. Additional model #2: cyclical (sine) tempo feature interacting with with `playlist_genre` interaction, plus main effects of other key audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3a9d6d-767c-49e3-94c9-c90262c34426",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_list[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1522b2b0-6a0e-4eba-b0db-4732de8fb09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_glm_8 = smf.logit(formula=formula_list[7], data=df_modeling).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced3909-b9f8-40d7-8c61-e7474eee7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling_copy['pred_probability_M8'] = fit_glm_8.predict(df_modeling)\n",
    "df_modeling_copy['pred_class_M8'] = np.where(df_modeling_copy.pred_probability_M8 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d90f0-00cb-450e-939e-2bddc1894e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(pd.crosstab(df_modeling_copy.binary_outcome, df_modeling_copy.pred_class_M8, margins=True),\n",
    "            annot=True, annot_kws={'size': 20}, fmt='3d')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55408787-273f-4299-be75-4d18d4095836",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8_results = fit_and_analyze_logistic(mod_name='Model 8', a_formula=formula_list[7], train_data=df_modeling, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c3507-1ea9-476e-8613-53c0d7693002",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f559fac6-7f19-4722-87ad-de9f5d290004",
   "metadata": {},
   "source": [
    "Model 8 was designed to test for a cyclical relationship between a song's tempo and its popularity. It has 15 coefficients, 9 of which are statistically significant. Below is the full list of all statistically significant features and their values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2064f9a-d60d-4ee7-b422-6b314298fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8_results['sign_coefs_&_their_values'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f9db5-e31b-4d64-86e1-431e0505334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8_results.top_2_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603f0e50-7bad-4786-b32c-7aa246338d2c",
   "metadata": {},
   "source": [
    "The key finding is that this model's central hypothesis was not supported by the data, as the cyclical tempo feature and its interactions were not statistically significant. Instead, the two most impactful predictors were the main effects for the genres, with rock (around  1.24) and pop (around 1.15) again showing the strongest positive association with popularity.\n",
    "\n",
    "The performance of this model is worse than other interaction models. The ROC AUC of 0.62 is low, and the model almost completely fails to identify popular songs, as shown by the near-zero sensitivity (around 0.007) and F1 Score (0.014). The low performance of the model confirms that this exploratory approach was not successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea55250e-6aa8-4b17-963c-ca7724283dc3",
   "metadata": {},
   "source": [
    "### Comparing the models' performance on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8673acc7-7c1a-4054-a603-fcac4b689eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "\n",
    "for m in range(len(formula_list)):\n",
    "    \n",
    "    results_list.append( fit_and_analyze_logistic(m+1, formula_list[m], train_data = df_modeling, threshold = 0.5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0444e7d4-de08-4160-aef4-523649599f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat(results_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b937ca-599a-4adf-83be-cf4852d0fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by=['Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd2efdf-106e-4bfd-b8b1-51b4cccb7c22",
   "metadata": {},
   "source": [
    "The most complex model - Model 6 - stands as the most accurate. However, when evaluating model performance, the ROC AUC is the most reliable metric for this dataset due to the significant class imbalance (67% of songs are unpopular). Because accuracy can be misleading, so I'm going to focus on the ROC AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991172ea-1e09-4eee-af8d-9c28b87cceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by=['ROC_AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdabb8a-880f-42f3-b1a9-4a8d849928d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic_make_roc (mod_name, a_formula, train_data):\n",
    "    a_mod = smf.logit(formula=a_formula, data=train_data).fit()\n",
    "\n",
    "    train_copy = train_data.copy()\n",
    "\n",
    "    train_copy['pred_probability'] = a_mod.predict(train_data)\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(train_data.binary_outcome.to_numpy(), train_copy.pred_probability.to_numpy())\n",
    "\n",
    "    res_df = pd.DataFrame({'tpr': tpr,\n",
    "                           'fpr': fpr,\n",
    "                           'threshold': threshold})\n",
    "\n",
    "    res_df['model_name'] = mod_name\n",
    "    res_df['model_formula'] = a_formula\n",
    "\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555b948-afbe-46d0-8e81-71b5f220e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_list = []\n",
    "\n",
    "for m in range( len(formula_list) ):\n",
    "    roc_list.append( fit_logistic_make_roc(m+1, formula_list[m], train_data=df_modeling) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44c350-52fd-4ea0-996e-8f43f6aa1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_df = pd.concat(roc_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f43a8a-4a61-4267-b143-c35f4c00b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_df['model_name'] = roc_df.model_name.astype('category')\n",
    "roc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eddefe-e1a4-4354-a89b-c0951fc66d03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.relplot(data=roc_df, x='fpr', y='tpr', hue='model_name',\n",
    "            kind='line', estimator=None, units='model_name',\n",
    "            col='model_name', col_wrap=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa28697-1652-4399-a02a-38920fd17732",
   "metadata": {},
   "source": [
    "The ROC curve for the intercept-only Model 1 is a 45-degree diagonal line, which is the expected result for a baseline model with no discriminative ability. Because it assigns the same probability to every song, it cannot distinguish between the positive and negative classes, resulting in an AUC of 0.5.\n",
    "\n",
    "In stark contrast, Model 6, the most complex model with 198 coefficients, has the curviest line - it is pushed furthest towards the top - left corner of the plot. This visually confirms it has the best performance on the training data, achieving the highest True Positive Rate for any given False Positive Rate, and thus the highest ROC AUC score. The other models\" curves fall in between these two extremes, generally showing improved performance as more features and complexity are added."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055509bb-d344-474d-94ed-aaf6cacfa6b8",
   "metadata": {},
   "source": [
    "#### Which model has the best performance on the training set?\n",
    "\n",
    "Based on the ROC AUC, Model 6 (the most complex model with the highest number of coefficients) has the best performance on the training set with a score of around 0.68. This indicates it has the strongest ability to distinguish between popular and unpopular songs out of all models tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96039770-2031-4aed-9e87-0594c6b1028c",
   "metadata": {},
   "source": [
    "#### Is the best model different when considering Accuracy vs ROC AUC?\n",
    "\n",
    "No, in this case, the best model is the same for both metrics. Model 6 also has the highest accuracy. However, ROC AUC is the better measure of performance here, as the high accuracy score is inflated by the model's ability to correctly guess the majority \"unpopular\" class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa696c-dc62-4f63-95a2-8d907fb51829",
   "metadata": {},
   "source": [
    "#### Is the best model better than the INTERCEPT-ONLY model?\n",
    "\n",
    "Yes, the best model is significantly better. Model 6's ROC AUC of roughly 0.68 demonstrates a clear improvement in predictive power over the intercept-only model's score of 0.5, which is equivalent to random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7de076-db33-4e0a-894b-7593e24ad7fb",
   "metadata": {},
   "source": [
    "#### How many coefficients are associated with the BEST model?\n",
    "\n",
    "The best-performing model, Model 6, is the most complicated one and has 198 coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26005e3-8e4e-4901-b007-3653edce98a9",
   "metadata": {},
   "source": [
    "## D. Models: Predictions\n",
    "\n",
    "### Creating the input grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c21a580-7976-4c65-a2f3-c0ac5448708c",
   "metadata": {},
   "source": [
    "The model with all inputs and linear additive features is Model 4 and the model that peformed best on the trainig set is Model 6. I will use them for predictions on the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6edf4e-6bdc-43c5-b81f-1b5797640189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_4_results.model_formula[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141201e6-98d5-4c12-a364-83640757b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6_results.model_formula[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba324b4c-c7de-4b99-a175-fd55cd3d955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_results['sign_coefs_&_their_values'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e695f9-484c-49ad-92e7-876cdfea63e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6_results['sign_coefs_&_their_values'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0abfb9-072e-4558-8eda-50ef46fd17a4",
   "metadata": {},
   "source": [
    "In both models, the three most important statistically significant inputs are `playlist_genre`, `energy`, and `loudness`. When comparing the main effects for `energy` and `loudness` across both Model 4 and Model 6, the `loudness` coefficient in Model 4 has the single highest magnitude (around 0.33). Therefore, it was selected as the most impactful continuous feature of the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae36cd-dd81-4e45-b7e6-3212685c0f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_grid = pd.DataFrame([(danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo, \n",
    "                            duration_ms, playlist_genre, key, mode) \n",
    "                            for danceability in [df_modeling.danceability.mean()]\n",
    "                            for energy in np.linspace(df_modeling.energy.min(), df_modeling.energy.max(), num=5)\n",
    "                            for loudness in np.linspace(df_modeling.loudness.min(), df_modeling.loudness.max(), num=101)\n",
    "                            for speechiness in [df_modeling.speechiness.mean()]\n",
    "                            for acousticness in [df_modeling.acousticness.mean()]\n",
    "                            for instrumentalness in [df_modeling.instrumentalness.mean()]\n",
    "                            for liveness in [df_modeling.liveness.mean()]\n",
    "                            for valence in [df_modeling.valence.mean()]\n",
    "                            for tempo in [df_modeling.tempo.mean()]\n",
    "                            for duration_ms in [df_modeling.duration_ms.mean()]\n",
    "                            for playlist_genre in df_modeling.playlist_genre.unique()\n",
    "                            for key in df_modeling['key'].mode()\n",
    "                            for mode in df_modeling['mode'].mode()],\n",
    "                         columns=['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
    "                            'valence', 'tempo', 'duration_ms', 'playlist_genre', 'key', 'mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e7aa4-30bb-42a6-acbc-4972e0ed5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_grid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf5c40-7e5c-4d3f-aa63-7d260a72e5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_grid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217619ac-4fec-4bb4-929e-91adb466717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_grid.playlist_genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3a4a2-3fb3-4a2a-8cff-ff9744de0570",
   "metadata": {},
   "source": [
    "### Making predictions on the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95863755-420e-4494-b514-40a79ef39ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfviz = input_grid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9902d36-8f18-4368-8967-920d2baf1f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfviz['pred_probability_M4'] = fit_glm_4.predict(input_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be2b7c0-5271-45a5-a678-697c5309392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfviz['pred_probability_M6'] = fit_glm_6.predict(input_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a56fe-b879-45dc-8a78-2e03599d3354",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a137cb7-2d2f-48b7-820a-b37fbb6436a0",
   "metadata": {},
   "source": [
    "### Visualizing event probability\n",
    "\n",
    "The line plot below shows the probability estimated by Model 4 on the new data (input_grid). It is colored by 5 distinct values of `energy` and each facet represents a `playlist_genre`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f0e907-442e-46dc-9a05-4fa0dab1ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=dfviz, x='loudness', y='pred_probability_M4', hue='energy', col='playlist_genre',\n",
    "            kind='line', estimator=None, units='energy', palette='icefire', \n",
    "            col_wrap=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9645f5-fbb4-43e4-b41f-f5ea5d4a414c",
   "metadata": {},
   "source": [
    "For each playlist genre, the lines are upward-sloping, meaning that as loudness goes up, the probability of a track being popular increases. We can also see that as energy goes down, the probability of the track being popular increases. The shape of the curve and the spacing between the lines representing different energy levels are generally consistent across genres. This shows that Model 4 assumes the effect of each feature is the same regardless of the song's genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e6e78c-bde3-4584-9f1b-7ec1b117733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_results['sign_coefs_&_their_values'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2477b796-f321-4136-aa1f-81f324279b46",
   "metadata": {},
   "source": [
    "The plot below shows the event probabilities predicted by Model 6 on the new data. Each line corresponds to a different `energy` level, and the facets separate the predictions across the six playlist genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d467b5a-fb3a-4474-bf9c-71b3cee6d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=dfviz, x='loudness', y='pred_probability_M6', hue='energy', col='playlist_genre',\n",
    "           kind='line', estimator=None, units='energy', palette='icefire',\n",
    "           col_wrap=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031d8e37-c37a-415b-adee-703547e087b8",
   "metadata": {},
   "source": [
    "Similar to Model 4, the plots for Model 6 show that higher loudness and lower energy are generally associated with a higher probability of being popular. However, the key difference is that the shapes of these relationships now change for each genre.\n",
    "\n",
    "The steepness of the lines varies noticeably - they are steepest for pop, indicating that loudness has the strongest positive impact on popularity in that genre, but are flattest for rap, meaning loudness has a much weaker effect for rap music.\n",
    "\n",
    "We also observe larger differences in the spacing between the lines. For instance, the distance is largest for the rap genre and shortest for pop. This shows that the negative effect of energy on popularity is most pronounced for rap and least impactful for pop.\n",
    "\n",
    "The main trend is that Model 6 learns how an audio feature's importance changes for each specific genre, as opposed to Model 4's more rigid approach.\n",
    "\n",
    "In the plots for Model 6, we can see that for some genres, like pop, latin, and r&b, the predicted probabilities get much closer to 1 compared to other genres, like  edm. This suggests that the model is much more certain in predictions for those three genres. Model 4, in contrast, doesn't show the same level of variation in certainty. The varied reliability of Model 6 allows us to trust its predictions more for some categories than for others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36acf4-3ac2-4fbf-9c31-4d5a942ccc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6_results['sign_coefs_&_their_values'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a626f62-069a-4e22-8143-d7df0fe271d3",
   "metadata": {},
   "source": [
    "## E. Models: Performance and Validation\n",
    "\n",
    "### Select models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e24aa-662a-4d99-976b-b4ee3f4960f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df.sort_values(by=['num_coefs'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d98665d-6fae-4379-8e6b-494c504c559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dacc9e-7948-41d2-8239-22d5ff41adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5897aec6-a9a6-486e-a0e3-db1d1bb1e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_list[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f60b22-0dd2-4552-b0fc-71290441ef3a",
   "metadata": {},
   "source": [
    "I selected three models for cross-validation:\n",
    "* Model 6 - the model that has the best performance on the training set. It includes interaction between categorical and continuous inputs (including main effects)\n",
    "* Model 3 - a model that includes continuous inputs with linear additive features has just a few features (11)\n",
    "* Model 4 - a model that includes all inputs (continuous and categorical) with linear additive features. It's medium-to-high complexity model with 28 features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7634ced-1eea-44b3-99f8-90d8a9966723",
   "metadata": {},
   "source": [
    "### Perform cross-validation and calculate performance metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a68d25-042f-4e15-9299-63dd036be9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a40f021-922d-47e6-92da-4261e475a433",
   "metadata": {},
   "source": [
    "I will use 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4227ebb-5bf6-41b9-9278-411601c1cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a1af6-62f8-45cf-84c0-773dc0ed36a1",
   "metadata": {},
   "source": [
    "I will fit the models with statsmodels.\n",
    "\n",
    "In Section D at the preprocessing stage, I created a dataset `df_numeric_inputs` that includes only continuous input variables. I also performed log and cube root transformations on those variables whose distributions were strongly skewed. Thus, `df_numeric_inputs` is a dataset which already contains log/cube root transformed numeric input variables. \n",
    "\n",
    "`df_copy` is a cleaned dataset containing all variables (including those that were not used in the analysis).\n",
    "\n",
    "I will create the dataset `df_CV`, a list `input_names`, and an object `output name` that will be used in the arguments for the formula that will help streamline the process of cross-validation, standardization, and performance metrics calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1960ba5d-9b6e-4256-a3b9-8d4372445b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CV = df_numeric_inputs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c653af-adae-4936-a917-0549d6838a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CV['playlist_genre'] = df_copy.playlist_genre\n",
    "df_CV['mode'] = df_copy['mode']\n",
    "df_CV['key'] = df_copy.key\n",
    "df_CV['binary_outcome'] = df_copy.binary_outcome.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f04eb5-eb0e-48ad-a04a-e10b87751cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = df_CV.drop(columns=['binary_outcome']).columns.tolist() \n",
    "input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8104af-d3b2-4d4b-9670-2179be8d4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = 'binary_outcome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f121f5-949b-4fad-b5e9-eea5a78d2538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CV.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7345c6b0-d573-43b4-a850-b4ac220071b4",
   "metadata": {},
   "source": [
    "The function below automates the process of model training and evaluation by:\n",
    "1) Splitting the dataset into five folds,\n",
    "2) Standardizing continuous variables within each fold,\n",
    "3) Fitting a logistic regression model on the training set,\n",
    "4) Predicting outcomes for the test set, and\n",
    "5) Calculating performance metrics, including accuracy, sensitivity, precision, specificity, FPR, F1 score, and ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82abb284-d9e9-4fd6-8076-8484a8bbc6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_and_asses_logistic_with_cv(mod_name, a_formula, data_df, x_names, y_name, cv, threshold=0.5):\n",
    "    # Initialize a list for each performance metric to store the results from each fold\n",
    "    accuracy_res = []\n",
    "    sensitivity_res = []\n",
    "    precision_res = []\n",
    "    specificity_res = []\n",
    "    fpr_res = []\n",
    "    f1_res = []\n",
    "    roc_auc_res = []\n",
    "\n",
    "    # Get the names of the continuous variables that need standardizing\n",
    "    continuous_vars = data_df[x_names].select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "    # Split the data and iterate over the folds\n",
    "    for train_id, test_id in cv.split( data_df.to_numpy(), data_df[y_name].to_numpy() ):\n",
    "        # subset the training and test splits within each fold\n",
    "        train_data = data_df.iloc[train_id].copy()\n",
    "        test_data = data_df.iloc[test_id].copy()\n",
    "\n",
    "        # Standardize the data within each split\n",
    "        scaler = StandardScaler()\n",
    "        # Fit the scaler only on the training data to avoid data leakage\n",
    "        scaler.fit(train_data[continuous_vars])\n",
    "        # Use the fitted scaler to transform both the training and testing data\n",
    "        train_data[continuous_vars] = scaler.transform(train_data[continuous_vars])\n",
    "        test_data[continuous_vars] = scaler.transform(test_data[continuous_vars])\n",
    "\n",
    "        # Fit the model on the training data within the current fold\n",
    "        a_mod = smf.logit(formula=a_formula, data=train_data).fit()\n",
    "\n",
    "        # Predict the test dataset within each fold\n",
    "        test_copy = test_data.copy()\n",
    "        test_copy['pred_probability'] = a_mod.predict(test_data)\n",
    "        test_copy['pred_class'] = np.where(test_copy.pred_probability > threshold, 1, 0)\n",
    "\n",
    "        # Calculate all performance metrics on the testing set\n",
    "        TN, FP, FN, TP = confusion_matrix(test_copy[y_name].to_numpy(), test_copy.pred_class.to_numpy() ).ravel()\n",
    "\n",
    "        Accuracy = (TN + TP) / (TN + FP + FN + TP) \n",
    "        Sensitivity = TP / (TP + FN) \n",
    "        Precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        Specificity = TN / (TN + FP)\n",
    "        FPR = 1 - Specificity\n",
    "        F1_Score = 2 * (Precision * Sensitivity) / (Precision + Sensitivity) if (Precision + Sensitivity) > 0 else 0\n",
    "        ROC_AUC = roc_auc_score(test_copy[y_name].to_numpy(), test_copy.pred_probability.to_numpy())\n",
    "\n",
    "        # Append the results for this fold to our lists\n",
    "        accuracy_res.append(Accuracy)\n",
    "        sensitivity_res.append(Sensitivity)\n",
    "        precision_res.append(Precision)\n",
    "        specificity_res.append(Specificity)\n",
    "        fpr_res.append(FPR)\n",
    "        f1_res.append(F1_Score)\n",
    "        roc_auc_res.append(ROC_AUC)\n",
    "\n",
    "    # Bookkeeping to store the results\n",
    "    results_dict = {'model_name': mod_name,\n",
    "                    'model_formula': a_formula,\n",
    "                    'num_coefs': len(a_mod.params),\n",
    "                    'fold_id': list(range(1, len(accuracy_res) + 1)),\n",
    "                    'Accuracy': accuracy_res,\n",
    "                    'Sensitivity': sensitivity_res,\n",
    "                    'Precision': precision_res,\n",
    "                    'Specificity': specificity_res,\n",
    "                    'FPR': fpr_res,\n",
    "                    'F1 Score': f1_res,\n",
    "                    'ROC AUC': roc_auc_res}\n",
    "    \n",
    "    # Convert the dictionary to a DataFrame\n",
    "    test_df = pd.DataFrame(results_dict)\n",
    "    \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2858968-e3d9-4cef-9998-9779116eb378",
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_CV = train_test_and_asses_logistic_with_cv('Model 3', formula_list[2], data_df=df_CV, x_names=input_names, y_name=output_name, cv=kf, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3284ce-6841-4f2c-8e66-3ec0c82b067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "M4_CV = train_test_and_asses_logistic_with_cv('Model 4', formula_list[3], data_df=df_CV, x_names=input_names, y_name=output_name, cv=kf, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e15f62-26ee-4ac7-8dd4-42421be63f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "M6_CV = train_test_and_asses_logistic_with_cv('Model 6', formula_list[5], data_df=df_CV, x_names=input_names, y_name=output_name, cv=kf, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9f6c0-ce9d-4eab-a84a-ea9cba538344",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_results = pd.concat([M3_CV, M4_CV, M6_CV], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f1b6f-4303-49d4-9cc5-d348fa0e31e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e3f513-a33d-41c4-a05e-77ec0614bcd8",
   "metadata": {},
   "source": [
    "### Visualizing the cross-validation results\n",
    "\n",
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d5daf3-44c3-4c08-85c0-a408e81346ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=CV_results, x='model_name', y='Accuracy', kind='point', join=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67fcd2-9c2b-457e-a171-88f1010aa2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CV.binary_outcome.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff67b4c-65b2-4f56-941a-8b74936f832b",
   "metadata": {},
   "source": [
    "While Model 6 has the highest mean value of accuracy, its 95% CI largely overlaps with other models, indicating no statistically significant difference. More importantly, because the dataset is imbalanced (over 67% of songs are unpopular), accuracy is a misleading metric. Therefore, I will focus on ROC AUC, which provides a more reliable measure of a model's ability to distinguish between classes, regardless of the classification threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9403a3-c84a-4549-8025-87e8200a6752",
   "metadata": {},
   "source": [
    "#### ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2a9df-5025-4ecf-ad36-7d05e92fd0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=CV_results, x='model_name', y='ROC AUC', kind='point', join=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e161a886-6b22-4b9a-a883-5bb898a18534",
   "metadata": {},
   "source": [
    "The cross-validation results show that all three models have an average ROC AUC score significantly above 0.5, indicating they all possess predictive power better than random chance. While Model 6 has the highest mean ROC AUC, its 95% confidence interval has a substantial overlap with that of Model 4. This suggests there is no statistically significant difference in performance between these two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4553877e-3c4b-4b49-855c-152556fd18c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab1c43c-ff1d-407e-b2d5-a485c7053d8e",
   "metadata": {},
   "source": [
    "### Which model is the BEST according to CROSS-VALIDATION?\n",
    "\n",
    "To determine the best model, I will focus on the ROC AUC score. Given that the dataset is imbalanced (over 67% of songs being unpopular), Accuracy is a misleading metric. The ROC AUC provides a more reliable assessment of a model's ability to discriminate between classes.\n",
    "\n",
    "The point plot of the cross-validation results shows that Model 6 has the highest average ROC AUC. However, its 95% confidence interval substantially overlaps with that of Model 4. This overlap indicates that there is no statistically significant difference in performance between the two models.\n",
    "\n",
    "Therefore, following the the \"simplest best\" rule, Model 4 is the best model according to cross-validation. While its performance is similar to the much more complex Model 6, it achieves this with only 28 coefficients compared to Model 6's 198 features. This makes Model 4 less prone to overfitting and more easily interpretable.\n",
    "\n",
    "### Is this model DIFFERENT from the model identified as the BEST according to the training set?\n",
    "\n",
    "Yes, the best model according to the cross-validation is Model 4 while the best model according to the training set is Model 6.\n",
    "\n",
    "### How many regression coefficients are associated with the best model?\n",
    "\n",
    "Model 4 has 28 coefficients.\n",
    "\n",
    "### Differences between the best model's performance on the training set vs cross-validation\n",
    "To see how performance of Model 4 changed from the training set to the cross-validation, I will compare its training set metrics with the averages for all metrics across all 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6718b40-b13d-489b-8e10-c89a8863002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df.model_name == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9492192-d67f-4606-a04f-b0f9dc8fab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_results = CV_results[CV_results['model_name'] == 'Model 4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7553bdd7-9975-42cf-ac99-548c443fa5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "M4_average_performance_CV = model_4_results[['Accuracy', 'Sensitivity', 'Precision', 'Specificity', 'FPR', 'F1 Score', 'ROC AUC']].mean()\n",
    "M4_average_performance_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8044a25-3b0e-4ecb-a8e8-82dba49cacb4",
   "metadata": {},
   "source": [
    "The slight decrease in metrics like ROC AUC and Accuracy during cross-validation is indicates a minor degree of overfitting. We also see some small fluctuations in the other metrics which is expected. The model performed slightly better on the data it had already seen, and the cross-validation score is a more reliable assessment of its predictive ability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a3794d-2560-4d2d-a28c-31a9b250c19b",
   "metadata": {},
   "source": [
    "### Applying the best model on the entire dataset\n",
    "\n",
    "To see the final set of coefficients for Model 4, which cross-validation identified as the best model, I re-fitted it on the entire preprocessed `df_modeling` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79dc8e-6870-44a1-bf0b-4c199c5e4e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = smf.logit(formula=formula_list[3], data=df_modeling).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00580adf-865a-4090-b09f-388ab8b1ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0fa243-b5cc-4992-9d2f-ad0615cb24fa",
   "metadata": {},
   "source": [
    "The statistically significant coefficients, ranked by the magnitude of their effect, are shown below. We see that `playlist_genre`, `loudness`, and `energy` have the biggest effect. However, we can also see that the effect of the `playlist_genre` is not universal across genres and are bigger for rock and pop compared to the edm baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0454bd73-de9a-4fb8-83d5-8e492af72344",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(best_model.params[best_model.pvalues < 0.05]).sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
